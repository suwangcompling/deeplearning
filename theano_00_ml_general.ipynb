{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/ML_GENERAL/PYTHON_IMPL/DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle, gzip\n",
    "import numpy as np\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "data_train, data_dev, data_test = cPickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shared_dataset(data):\n",
    "    X, Y = data\n",
    "    sharedX = theano.shared(np.asarray(X,dtype=theano.config.floatX))\n",
    "    sharedY = theano.shared(np.asarray(Y,dtype=theano.config.floatX))\n",
    "    return sharedX, T.cast(sharedY, 'int32') # y's are labels, makes sense to store them as ints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SPLIT DATA AS SHARED (FOR PUBLIC ACCESS LATER)\n",
    "X_train, Y_train = shared_dataset(data_train)\n",
    "X_dev, Y_dev = shared_dataset(data_dev)\n",
    "X_test, Y_test = shared_dataset(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50000   784] [50000]\n",
      "[10000   784] [10000]\n",
      "[10000   784] [50000]\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape.eval(), Y_train.shape.eval()\n",
    "print X_dev.shape.eval(), Y_dev.shape.eval()\n",
    "print X_test.shape.eval(), Y_train.shape.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500 784] [500]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(7, dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACCESS A BATCH\n",
    "batchSize = 500\n",
    "thirdBatchX = X_train[2*batchSize : 3*batchSize]\n",
    "thirdBatchY = Y_train[2*batchSize : 3*batchSize]\n",
    "print thirdBatchX.shape.eval(), thirdBatchY.shape.eval()\n",
    "thirdBatchY[1].eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Loss Functions\n",
    "\n",
    "NB: $k$ can be interpreted as the index for *label*, $i$ as the index for *data point*.\n",
    "\n",
    "**a. Zero-One Loss (nondifferentiable)**\n",
    "* $ L = \\sum_{i=0}^{|D|} I_{f(x_i)\\neq y_i} $, where $ f(x) = argmax_k P(y=k|x,\\theta) $\n",
    "\n",
    "**b. Negative Log-Likelihood Loss (differentiable)**\n",
    "* $ L = -\\sum_{i=0}^{|D|} log P(Y = y_i | x_i, \\theta) $, where $P \\in [0,1] \\Rightarrow log(P) \\in [\\infty,0] \\Rightarrow -log(P) \\in [0, \\infty]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ZERO-ONE LOSS\n",
    "zeroOneLoss = T.sum(T.neq(T.argmax(pYgivenX), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEG LL LOSS\n",
    "nll = -T.sum(T.log(pYgiveX)[T.arange(y.shape[0]), y]) # retrieve the logP of the correct y labels.\n",
    "    # vector-indexing:\n",
    "    #  m = np.array(range(12)).reshape(3,4)\n",
    "    #  array([[ 0,  1,  2,  3],\n",
    "    #         [ 4,  5,  6,  7],\n",
    "    #         [ 8,  9, 10, 11]])\n",
    "    #  m[[0,1,2],[0,1,2]]\n",
    "    #  array([ 0,  5, 10]) <= m[0,0], m[1,1], m[2,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Learning Algorithms\n",
    "\n",
    "**a. Vanilla Gradient Descent**\n",
    "* Update: $ \\theta_{k+1} = \\theta_k - \\eta\\frac{\\partial C(\\theta_k)}{\\partial \\theta_k} $*\n",
    "* Cycle: Grand update after each run of the entire dataset. \n",
    "\n",
    "**b. Single Stochastic Gradient Descent**\n",
    "* Update: $ \\theta_{k+1} = \\theta_k - \\eta\\frac{\\partial L(\\theta_k, data_i)}{\\partial\\theta_k} $\n",
    "* Cycle: Update for each data point.\n",
    "\n",
    "**b. Batch Stochastic Gradient Descent**\n",
    "* Update: $ \\theta_{k+1} = \\theta_k - \\eta\\frac{1}{m}\\sum_{i=0}^{m}\\frac{\\partial L(\\theta_k, data_i)}{\\partial\\theta_k} $\n",
    "* Cycle: Update (w/ average gradient) for each batch of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Momentum\n",
    "\n",
    "* Tuning: Controling the extent to which update inertiaing along the previous direction.\n",
    "* $ \\Delta\\theta_{k+1} = \\alpha\\Delta\\theta_k + (1-\\alpha)\\frac{\\partial L(\\theta_k,data_i)}{\\partial\\theta_k} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Regularization\n",
    "\n",
    "* Tuning: Controling the magnitude of weights, avoid overfitting.\n",
    "* $ L = L + \\lambda\\parallel\\theta\\parallel_p^p $, where $\\parallel\\theta\\parallel_p = (\\sum_{j=0}^{|\\theta|} |\\theta_j|^p)^\\frac{1}{p}$\n",
    "* L1/2 Regularization: $p = 1$/$p=2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Early Stopping\n",
    "\n",
    "* Tuning: Avoid overfitting by stopping when a model's performance ceaces to improve sufficiently (by some threshold) on the development set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SAVE\n",
    "saveFile = open('path', 'wb')\n",
    "cPickle.dump(W.get_value(borrow=True), saveFile, -1)\n",
    "cPickle.dump(B.get_value(borrow=True), saveFile, -1)\n",
    "    # borrow=True: occupied memory is available for use (more efficient when keeping original space is not necessary).\n",
    "    # -1: HIGHEST_PROTOCOL flag, more efficient storage than numpy's default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# READ\n",
    "saveFile = open('path')\n",
    "W.set_value(cPickle.load(saveFile), borrow=True)\n",
    "B.set_value(cPickle.load(saveFile), borrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
